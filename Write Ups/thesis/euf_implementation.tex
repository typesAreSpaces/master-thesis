\section{Implementation}

The description of the interpolation algorithm presented in the
previous section suggests a straight forward implementation
of the first two stages using well-known algorithms 
\cite{10.1145/322186.322198,10.1145/322217.322228} 
and data structures from the SMT
solver Z3 \cite{10.1007/978-3-540-78800-3_24} to represent 
elements from the EUF language. One particular change was 
required in the congruence closure algorithm since Kapur's 
algorithm keeps common terms as representatives
whenever common terms belong to a partition of terms induced
by the equivalence relation.

The algorithm in \cite{10.1145/322217.322228}
uses a union-find data structure to encode the equivalence classes
of the nodes in the abstract syntax tree of the input formula with 
a `modify the smaller subtree' strategy. This means that
when two nodes $u, v$ in the abstract syntax tree are
meant to be merged, the representative of the new 
combined equivalence class is the node which has a bigger
numbers of predecessors nodes in the abstract
syntax tree pointing to the
equivalence class of the node. The idea was to update the least
amount of nodes that possibly can change representatives
due to the most recent merge operation of the equivalence classes 
and congruence.

\begin{notation}
  Given a theory $\mathcal{E}$ and a term $u$ in the language of 
  $\mathcal{E}$, we can indicate by $[u]$ the equivalence class
  induced by $\mathcal{E}$, i.e. $[u]_{\mathcal{E}} = \{ v \in TERMS | 
  \models_{\mathcal{E}} u = v\}$ \footnote{If the theory
    is clear from context, the notation $[u]$
  denotes the equivalence class of $u$.}
\end{notation}

Our algorithm uses a difference partial order to 
maintain common terms as representatives of 
the equivalence classes. The non-reflexive relation 
$\succ_{common}$ 
\footnote{The reflexive relation $u \succeq_{common} v$
  is defined as $u = v \lor u \succ_{common} v$, where
  the equality between nodes is defined as $|list(u)| = 
  |list(v)| \land u$ is a common term $\iff$ 
  $v$ is a common term.
}
is defined for all nodes $u, v$ in the abstract syntax 
tree of terms as:

\begin{equation*}
  u \succ_{common} v = \begin{cases} 
    |list(u)| > |list(v)| & \text{if }(u \text{ is a common term}\Leftrightarrow \\ 
    & v \text{ is a common term}) \\
    \text{u is a common term} & \text{otherwise}
  \end{cases}
\end{equation*}

where $list(u) = \{ f(u_1, \dots, u_n) \in \text{TERMS} 
| \exists u_i . u_i \in [u] ] \}$


In the next section we will discuss the changes proposed to 
Phase III in Kapur's algorithm. 

\subsection{New optimized conditional elimination 
and replacement step in Kapur's algorithm}

The modification of Phase III implemented in this thesis work
combines and extends the algorithms and data structures introduced
in \cite{GALLIER1987233, 10.1007/978-3-540-32033-3_33}.
The motivation behind the combination of these two procedures
is twofold: 

\begin{itemize}
  \item[] 1. First, we want to introduce 
    common equations from the antecedents of 
    the Horn clauses obtained during Phase II
    to a conditional equivalence relation as well
    as updating the conditional equivalence relation 
    structure by using the equation propagation mechanism
    from the congruence closure algorithm and 
    the implicational propagation component 
    from Gallier's structure.
  \item[] 2. Additionally, we want to find all the common
    Horn clauses provable from the original input 
    of equations. The Explain operator in 
    \cite{10.1007/978-3-540-32033-3_33} is recursively 
    used to construct 
    the antecedent of such Horn clauses during the 
    conditional replacement step. The Explain operator 
    traverses a proof-tree data structure containing the nodes
    that were used to combine equivalence classes 
    in the underlying union-find data structure.
    Thus, the MERGE operation in \cite{GALLIER1987233} is
    required to update the proof tree 
    \footnote{This structure is used in order to retrieve
    explanations.}
    from \cite{10.1007/978-3-540-32033-3_33} as well.
\end{itemize}

The thesis work accomplishes the previous
points by implementing the following:

\begin{itemize}
  \item[] 1. In addition to the parsing procedure
    and initialization of the Gallier data structure,
    we assert into the union-find data structure 
    every common equation in the 
    antecedent of a Horn clause.
  \item[] 2. The implemented C++ class for 
    the congruence closure with explanation 
    \footnote{
      A fragment of the actual code is shown
      at Section \ref{congruence_closure_label}.
    } 
    includes a pointer as data member to the 
    class implementation
    for the Gallier data structure in order to propagate 
    the equational information achieved during
    merges and updates due to congruence.
  \item[] 3. We implement th ExtendedExplain 
    procedure which returns a list of common equations
    when an equation given as input is provable in the 
    conditional equivalence relation. The pseudo-code
    for the ExtendedExplain procedure is shown below:
\end{itemize}

TODO: keep working here. Write the ExtendedExplain
procedure.

At the end of this algorithm we can identify 
\emph{usable Horn clauses} by checking the Horn clauses
with \emph{numargs} entries equal to 0. Nonetheless, these 
Horn clauses are not the
desired \emph{usable Horn clauses} because the 
unsatisfiability testing algorithm
did not update the antecedents of the Horn clauses. 
The main difficulty to design a data structure
for the latter to work inside the unsatisfiability 
testing algorithm was the queue data structure
only adds grounded equation whenever the truth 
value of the literal changes to true, which happens
during \emph{equational propagation} or during 
the \emph{implicational propagation} steps.
For the \emph{implicational propagation} the task is 
easy because we can know the clause
where the just new proven ground equation comes, 
but it cannot be the same situation
for the \emph{equational propagation} since this 
step relies on congruence closure.

To remedy this issue, we equip our congruence closure 
algorithm with the Explanation operator, so
we can recover the grounded equations needed to entail 
any particular grounded equation. Additionally,
this will require a data structure to maintain the Horn 
clauses for each grounded equation that
it is the head equation of. With the latter we can 
recover the Horn Clauses where each grounded
equation came from to update the antecedents and 
obtain \emph{usable Horn clauses}.

The algorithm appears below in pseudo-code notation:

\input{modified_unsatisfiability_testing_for_grounded_horn_clauses}
\input{modified_congruence_closure_with_explanation_algorithms_merge}
\input{modified_congruence_closure_with_explanation_algorithms_propagate}

\subsection{Ground Horn Clauses with Explanations}

We notice that, by removing our changes to the unsatisfiability testing
for grounded Horn clauses regarding uncommon symbols, we effectively combine
the congruence closure with explanations to the original unsatisfiability
testing algorithm. With the latter, we can query the membership of a Horn
clauses in a given user-defined theory and additionally obtain a proof of
the latter. This approach works by introducing the antecedent equations of
a grounded Horn clause as part of the user-defined theory in order to prove
its head equation. By the Deduction Theorem \cite{10.5555/1642730}, we can
recover a proof of the original queried Horn clause by removing the antecedent
equations appearing the proof given by the Explain operation.

\subsection{Conditional propagation in Kapur's algorithm}

Once the conditional congruence closure data structure is built after 
the execution of the previous step, we can compute conditional eliminations
as follows. For the latter, we will require the following auxiliary functions:

\input{auxiliary_function_candidates}
\input{auxiliary_function_auxiliar_explain}
\input{auxiliary_function_allcandidates}

\input{conditional_elimination_part_1}
\input{conditional_elimination_part_2}

The conditional propagation algorithm produces common Horn clauses from previous
uncommon equations and uncommon Horn clauses obtained in previous steps of Kapur's
algorithm. The are two main invariants for the Horn clauses formed by the
conditional propagation procedure: 

\begin{itemize}
  \item the antecedents are constructed using the \emph{Explain} operator, 
    which returns a sequence of common equations since these are the 
    only merged terms added at the beginning of the initialization 
    routine of the modified Gallier's data structure.

    An additional property must be checked when processing previous
    Horn clauses. The `previous' antecedent for these clauses must be \emph{explainable},
    which means that every equation in the antecedent must belong to the conditional
    congruence closure, otherwise an empty explaination will be produced by the
    \emph{Explain} operator. If a Horn clause antecedent is not \emph{explainable}
    the resulting Horn clause cannot be added to the final result.

  \item the consequents are constructed with the help of the \emph{Candidates},
    \emph{AllCandidates}, and the \emph{CartesianProd} operators. 
    The former is a function that takes as input
    a term and returns a list of common terms
    that belong to the equivalence relation of a given term if such term is uncommon,
    and return a list containing the term itself if the term is common; the 
    \emph{AllCandidates} function takes as input a function application term and
    constructs a list of lists with common terms that are equivalent to the arguments
    of the function application if the function symbol is common, and returns an empty
    list otherwise; \emph{CartesianProd} implements a cartesian product, i.e. it 
    produces a list of n-tuples given as input a list of $n$ list of terms (the 
      composition of \emph{CartesianProd} and \emph{AllCandidates} are meant to be
    used to produce a function application free of uncommon terms). Finally, the
    head equations for the new Horn clauses are obtained by equating the left-hand
    side common candidates and right-hand side common candidates obtained by these 
    procedures.

\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
